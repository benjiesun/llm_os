#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
llm_vllm.py
è¨€é“ OS â€” è°ƒç”¨æœåŠ¡å™¨ä¸Šè‡ªå»º vLLM æœåŠ¡çš„æ¨¡å—
åŠŸèƒ½ï¼š
- ä»…é€šè¿‡ HTTP æ¥å£ä¸æœåŠ¡å™¨ä¸Šçš„ llm_vllm_server.py äº¤äº’
- æ¥å£æ ¼å¼å…¼å®¹ OpenAI Chat Completions (/v1/chat/completions)
"""

import os
import requests
from dotenv import load_dotenv
from utils.prompt_loader import load_system_prompt

# ========= åŠ è½½ç¯å¢ƒå˜é‡ =========
load_dotenv()
LOCAL_ADDR = os.getenv("LOCAL_ADDR", "http://127.0.0.1:8000/v1")   # é»˜è®¤æœ¬æœºç«¯å£ï¼Œå¯ç”±å‰ç«¯è¾“å…¥
LOCAL_TIMEOUT = int(os.getenv("LOCAL_TIMEOUT", "60"))


# ========= æ ¸å¿ƒå‡½æ•° =========
def get_command_from_llm(prompt: str, system_type: str = None,
                         local_addr: str = None,
                         max_new_tokens: int = 512,
                         temperature: float = 0.7) -> str:
    """
    è°ƒç”¨æœåŠ¡å™¨ä¸Šçš„ llm_vllm_server.py æœåŠ¡ã€‚
    å‚æ•°ï¼š
        prompt: ç”¨æˆ·è¾“å…¥
        system_type: ç³»ç»Ÿç±»å‹ï¼ˆLinux/Windows/...ï¼‰
        local_addr: API åœ°å€ï¼Œå¦‚ http://192.168.1.10:8000/v1
    è¿”å›ï¼š
        å¤§æ¨¡å‹çš„å›å¤æ–‡æœ¬
    """
    addr = local_addr or LOCAL_ADDR
    base = addr.rstrip("/")
    url = f"{base}/chat/completions" if not base.endswith("/chat/completions") else base

    SYSTEM_PROMPT = load_system_prompt(system_type)
    headers = {"Content-Type": "application/json"}

    payload = {
        "model": "local-DeepSeek",
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
        "temperature": temperature,
        "max_tokens": max_new_tokens,
        "stream": False
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=LOCAL_TIMEOUT)
        response.raise_for_status()
        data = response.json()

        # å°è¯•ä»å“åº”ä¸­æå–æ–‡æœ¬
        if "choices" in data and len(data["choices"]) > 0:
            choice = data["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"].strip()
            elif "text" in choice:
                return choice["text"].strip()

        return str(data)
    except Exception as e:
        return f"âŒ æœ¬åœ° vLLM API è¯·æ±‚å¤±è´¥: {e}"


# ========= æµ‹è¯•è°ƒç”¨ =========
if __name__ == "__main__":
    user_input = "åˆ—å‡ºå½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"
    print("ğŸ§  è¾“å…¥ï¼š", user_input)
    print("ğŸ’¬ è¾“å‡ºï¼š")
    print(get_command_from_llm(
        user_input,
        system_type="Linux",
        local_addr="http://192.168.1.10:8000/v1"   # æ›¿æ¢ä¸ºä½ çš„æœåŠ¡å™¨åœ°å€
    ))
